{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengembangan dan Pengoperasian Sistem Machine Learning untuk Prediksi Keparahan Serangan Kecemasan\n",
    "\n",
    "- Nama: `Rendika Nurhartanto Suharto`\n",
    "- Username dicoding: ```RENDIKA NURHARTANTO SUHARTO```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import Library and Dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n proyek-akhir-mlops python=3.9.15 -y\n",
    "# conda activate proyek-akhir-mlops\n",
    "# pip install -r requirements.txt\n",
    "# pip install autopep8 pylint\n",
    "\n",
    "# conda create -n tfx-beam python=3.8.18 -y\n",
    "# conda activate tfx-beam\n",
    "# pip install -r requirements-2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "from typing import Text\n",
    "from absl import logging  # type: ignore\n",
    "from tfx.orchestration import metadata  # type: ignore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tfx.orchestration import pipeline as tfx_pipeline  # type: ignore\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Set Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan set variabel seperti pipeline name, path untuk menyimpan output, path module, dan banyak lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline and schema names\n",
    "PIPELINE_NAME = \"anxiety-pipeline\"  # Name of the main pipeline\n",
    "SCHEMA_PIPELINE_NAME = \"anxiety-tfdv-schema\"  # Name of the schema pipeline\n",
    "MODEL_NAME = \"anxiety-model\" # Name of the saved model\n",
    "\n",
    "# Directory for storing generated artifacts\n",
    "PIPELINE_ROOT = os.path.join('RENDIKA_NURHARTANTO_SUHARTO-pipeline', PIPELINE_NAME)  # Root directory for pipeline artifacts\n",
    "\n",
    "# Path to SQLite DB file for MLMD storage\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.sqlite')  # Path to metadata database\n",
    "\n",
    "# Output directory for exporting trained models\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model_dir', MODEL_NAME)  # Directory for saving trained models\n",
    "\n",
    "# Pipeline inputs\n",
    "DATA_ROOT = \"data\"  # Root directory for input data\n",
    "COMPONENTS_MODULE_FILE = \"modules/components.py\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/anxiety_transform.py\"  # Transformation logic module\n",
    "TRAINER_MODULE_FILE = \"modules/anxiety_trainer.py\"  # Model training logic module\n",
    "TUNER_MODULE_FILE = \"modules/anxiety_tuner.py\"  # Hyperparameter tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subdirectories\n",
    "project_root = \"C:/Users/rendi/ITTS DATA SCIENCE/Semester 8\\MLOps - Dicoding Bonus Course/2. Proyek Akhir - Proyek Pengembangan dan Pengoperasian Sistem Machine Learning\"\n",
    "modules_dir = os.path.join(project_root, \"modules\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(modules_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Checking and Processing Dataset with Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Anxiety Attack : Factors, Symptoms, and Severity\n",
    "\n",
    "**Data Format**: CSV (Comma-Separated Values)\n",
    "\n",
    "**Size**: 12,000+ records\n",
    "\n",
    "**Usability in Kaggle**: 10.00\n",
    "\n",
    "**Description**: This dataset contains over **12,000 records** detailing various factors related to anxiety attacks, including demographics, lifestyle habits, stress levels, and physiological responses. It is designed for **data analysis**, **machine learning**, and **mental health research** to explore patterns, triggers, and potential correlations in anxiety disorders.\n",
    "\n",
    "**Key Features**:\n",
    "\n",
    "üßë‚Äçü§ù‚Äçüßë Demographics: Age, Gender, Occupation\n",
    "\n",
    "üåô Lifestyle Factors: Sleep, Physical Activity, Diet, Caffeine & Alcohol Intake\n",
    "\n",
    "üíì Health Indicators: Heart Rate, Breathing Rate, Sweating, Dizziness\n",
    "\n",
    "üß† Psychological Factors: Stress Level, Family History, Therapy & Medication\n",
    "\n",
    "‚ö†Ô∏è Anxiety Attack Severity: Scale from 1 to 10\n",
    "\n",
    "**Feature Explaination**:\n",
    "\n",
    "| **Feature**                  | **Description**                                                            |\n",
    "| ----------------------------: | -------------------------------------------------------------------------- |\n",
    "| `ID`                         | Unique identifier for each record                                          |\n",
    "| `Age`                        | Age of the individual (18 to 64 years)                                     |\n",
    "| `Gender`                     | Gender of the individual (Male, Female, Other)                             |\n",
    "| `Occupation`                 | Job role of the individual                                                 |\n",
    "| `Sleep Hours`                | Daily sleep duration (in hours)                                            |\n",
    "| `Physical Activity`          | Weekly exercise duration (in hours)                                        |\n",
    "| `Caffeine Intake`            | Daily caffeine intake (in mg)                                              |\n",
    "| `Alcohol Consumption`        | Weekly alcohol consumption (in drinks)                                     |\n",
    "| `Smoking`                    | Whether the individual smokes (Yes/No)                                      |\n",
    "| `Family History of Anxiety`  | Whether the individual has a family history of anxiety (Yes/No)            |\n",
    "| `Stress Level`               | Stress level (scale from 1 to 10)                                          |\n",
    "| `Heart Rate`                 | Heart rate (bpm) during an anxiety attack                                  |\n",
    "| `Breathing Rate`             | Breathing rate (breaths per minute) during an anxiety attack               |\n",
    "| `Sweating Level`             | Sweating level (scale from 1 to 5)                                         |\n",
    "| `Dizziness`                  | Whether dizziness was experienced during the attack (Yes/No)               |\n",
    "| `Medication`                 | Whether the individual is on medication for anxiety (Yes/No)               |\n",
    "| `Therapy Sessions`           | Number of therapy sessions attended per month                              |\n",
    "| `Recent Major Life Event`    | Whether the individual has experienced a recent major life event (Yes/No)  |\n",
    "| `Diet Quality`               | Quality of the individual's diet (scale from 1 to 10)                      |\n",
    "| `Severity of Anxiety Attack` | Severity of the anxiety attack (scale from 1 to 10)                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset\n",
    "data_check = pd.read_csv(\"anxiety_attack_dataset.csv\").drop(columns = \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Physical Activity (hrs/week)</th>\n",
       "      <th>Caffeine Intake (mg/day)</th>\n",
       "      <th>Alcohol Consumption (drinks/week)</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Family History of Anxiety</th>\n",
       "      <th>Stress Level (1-10)</th>\n",
       "      <th>Heart Rate (bpm during attack)</th>\n",
       "      <th>Breathing Rate (breaths/min)</th>\n",
       "      <th>Sweating Level (1-5)</th>\n",
       "      <th>Dizziness</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Therapy Sessions (per month)</th>\n",
       "      <th>Recent Major Life Event</th>\n",
       "      <th>Diet Quality (1-10)</th>\n",
       "      <th>Severity of Anxiety Attack (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467</td>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>471</td>\n",
       "      <td>16</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>Student</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>364</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender Occupation  Sleep Hours  Physical Activity (hrs/week)  \\\n",
       "0   56  Female      Other          9.6                           8.3   \n",
       "1   46    Male    Teacher          6.4                           7.3   \n",
       "2   32  Female     Doctor          6.9                           1.0   \n",
       "3   60    Male     Doctor          9.2                           3.7   \n",
       "4   25    Male    Student          9.2                           2.5   \n",
       "\n",
       "   Caffeine Intake (mg/day)  Alcohol Consumption (drinks/week) Smoking  \\\n",
       "0                       175                                  6      No   \n",
       "1                        97                                  6      No   \n",
       "2                       467                                 14      No   \n",
       "3                       471                                 16      No   \n",
       "4                       364                                  2      No   \n",
       "\n",
       "  Family History of Anxiety  Stress Level (1-10)  \\\n",
       "0                        No                    4   \n",
       "1                        No                    3   \n",
       "2                        No                    2   \n",
       "3                       Yes                    6   \n",
       "4                       Yes                    7   \n",
       "\n",
       "   Heart Rate (bpm during attack)  Breathing Rate (breaths/min)  \\\n",
       "0                             145                            33   \n",
       "1                             143                            18   \n",
       "2                              60                            34   \n",
       "3                              94                            19   \n",
       "4                             152                            15   \n",
       "\n",
       "   Sweating Level (1-5) Dizziness Medication  Therapy Sessions (per month)  \\\n",
       "0                     3        No         No                             4   \n",
       "1                     5       Yes         No                             0   \n",
       "2                     1        No         No                             7   \n",
       "3                     1        No        Yes                             4   \n",
       "4                     4        No        Yes                             0   \n",
       "\n",
       "  Recent Major Life Event  Diet Quality (1-10)  \\\n",
       "0                     Yes                    9   \n",
       "1                      No                    9   \n",
       "2                     Yes                   10   \n",
       "3                     Yes                    5   \n",
       "4                      No                    1   \n",
       "\n",
       "   Severity of Anxiety Attack (1-10)  \n",
       "0                                 10  \n",
       "1                                  8  \n",
       "2                                  5  \n",
       "3                                  8  \n",
       "4                                  1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check the first 5 rows of the dataset\n",
    "data_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Age', 'Gender', 'Occupation', 'Sleep Hours',\n",
      "       'Physical Activity (hrs/week)', 'Caffeine Intake (mg/day)',\n",
      "       'Alcohol Consumption (drinks/week)', 'Smoking',\n",
      "       'Family History of Anxiety', 'Stress Level (1-10)',\n",
      "       'Heart Rate (bpm during attack)', 'Breathing Rate (breaths/min)',\n",
      "       'Sweating Level (1-5)', 'Dizziness', 'Medication',\n",
      "       'Therapy Sessions (per month)', 'Recent Major Life Event',\n",
      "       'Diet Quality (1-10)', 'Severity of Anxiety Attack (1-10)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Check columns of the dataset\n",
    "print(f\"Columns: {data_check.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Age                                12000 non-null  int64  \n",
      " 1   Gender                             12000 non-null  object \n",
      " 2   Occupation                         12000 non-null  object \n",
      " 3   Sleep Hours                        12000 non-null  float64\n",
      " 4   Physical Activity (hrs/week)       12000 non-null  float64\n",
      " 5   Caffeine Intake (mg/day)           12000 non-null  int64  \n",
      " 6   Alcohol Consumption (drinks/week)  12000 non-null  int64  \n",
      " 7   Smoking                            12000 non-null  object \n",
      " 8   Family History of Anxiety          12000 non-null  object \n",
      " 9   Stress Level (1-10)                12000 non-null  int64  \n",
      " 10  Heart Rate (bpm during attack)     12000 non-null  int64  \n",
      " 11  Breathing Rate (breaths/min)       12000 non-null  int64  \n",
      " 12  Sweating Level (1-5)               12000 non-null  int64  \n",
      " 13  Dizziness                          12000 non-null  object \n",
      " 14  Medication                         12000 non-null  object \n",
      " 15  Therapy Sessions (per month)       12000 non-null  int64  \n",
      " 16  Recent Major Life Event            12000 non-null  object \n",
      " 17  Diet Quality (1-10)                12000 non-null  int64  \n",
      " 18  Severity of Anxiety Attack (1-10)  12000 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# 4. Check the summary of the dataset\n",
    "data_check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Check for duplicate data in the dataframe\n",
    "data_check.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the severity of anxiety attack into categories - reference: https://www.therecoveryvillage.com/mental-health/anxiety/levels-of-anxiety/\n",
    "\n",
    "def categorize_anxiety(severity):\n",
    "    if severity <= 3:\n",
    "        return 'Mild Anxiety'\n",
    "    elif 4 <= severity <= 6:\n",
    "        return 'Moderate Anxiety'\n",
    "    elif 7 <= severity <= 9:\n",
    "        return 'Severe Anxiety'\n",
    "    else:\n",
    "        return 'Panic Level Anxiety'\n",
    "\n",
    "# 6. Apply the function to create a new column for anxiety category\n",
    "data_check['Anxiety Category'] = data_check['Severity of Anxiety Attack (1-10)'].apply(categorize_anxiety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mild Anxiety': 0,\n",
       " 'Moderate Anxiety': 1,\n",
       " 'Panic Level Anxiety': 2,\n",
       " 'Severe Anxiety': 3}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data_check['Anxiety Category Encoded'] = label_encoder.fit_transform(data_check['Anxiety Category'])\n",
    "\n",
    "# Display Mapping the label encoding results\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Drop the Severity of Anxiety Attack (1-10) column\n",
    "data_check.drop(columns = \"Severity of Anxiety Attack (1-10)\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save the processed data to a new CSV file\n",
    "data_check.to_csv('data/anxiety_attack_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Membuat Pipeline TFX Interaktif dengan Komponen-Komponen Utama***\n",
    "\n",
    "Pipeline ini terdiri dari beberapa komponen utama *TFX* yang saling berhubungan untuk *membangun*, *melatih*, dan *mengevaluasi* model machine learning. Setiap komponen akan dijelaskan secara detail dengan contoh kode yang dilengkapi dengan **magic command** untuk membuat modul Python. *Pipeline* ini bersifat modular dan dapat disesuaikan dengan kebutuhan proyek Anda. Magic command seperti *%%writefile* mempermudah pembuatan modul khusus untuk komponen seperti *Transform*, *Trainer*, dan *Tuner*.\n",
    "\n",
    "1. ```CsvExampleGen``` -> Digunakan untuk membaca data dan membaginya menjadi dua bagian: training dan evaluation.\n",
    "2. ```StatisticsGen``` -> Menghasilkan statistik data yang digunakan untuk analisis lebih lanjut dan pembuatan skema data.\n",
    "3. ```SchemaGen``` -> Membuat skema untuk dataset berdasarkan statistik yang dihitung pada langkah sebelumnya, untuk memastikan data yang masuk sesuai dengan harapan.\n",
    "4. ```ExampleValidator``` -> Memvalidasi data menggunakan skema yang telah dibuat untuk memastikan kualitas dan konsistensi data.\n",
    "5. ```Transform``` -> Melakukan transformasi pada data (misalnya, normalisasi atau encoding), guna menyiapkan data untuk pelatihan.\n",
    "6. ```Tuner``` -> Mencari hyperparameter terbaik untuk model, sehingga model dapat mencapai performa optimal berdasarkan dataset.\n",
    "7. ```Trainer``` -> Melatih model menggunakan data yang telah ditransformasi dan hyperparameter terbaik yang ditemukan oleh Tuner.\n",
    "8. ```Evaluator``` -> Mengevaluasi model yang telah dilatih menggunakan berbagai metrik kinerja, seperti Accuracy atau AUC.\n",
    "9. ```Pusher``` -> Menyimpan dan mendistribusikan model terlatih jika model memenuhi kriteria evaluasi.\n",
    "\n",
    "Komponen trainer sudah menggunakan komponen tuner. Pusher akan melakukan push model jika melebihi syarat dari BinaryAccuracy ```0.9```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Inisialisasi Komponen TFX untuk Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/components.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {COMPONENTS_MODULE_FILE}\n",
    "\"\"\"\n",
    "components.py\n",
    "\n",
    "Modul ini berisi fungsi untuk inisialisasi komponen TFX dalam pipeline ML.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import (\n",
    "    CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator,\n",
    "    Transform, Trainer, Tuner, Evaluator, Pusher\n",
    ")\n",
    "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
    "    LatestBlessedModelStrategy\n",
    ")\n",
    "\n",
    "def init_components(config):\n",
    "    \"\"\"\n",
    "    Inisialisasi dan mengembalikan komponen TFX untuk pipeline.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Konfigurasi pipeline yang mencakup path modul, jumlah langkah pelatihan,\n",
    "                       path data, dan direktori model serving.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Komponen-komponen TFX yang siap digunakan dalam pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Konfigurasi split dataset: 90% training, 10% evaluasi\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=9),\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=1)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # 2. Komponen ExampleGen\n",
    "    example_gen = CsvExampleGen(input_base=config[\"DATA_ROOT\"], output_config=output)\n",
    "\n",
    "    # 3. Komponen StatisticsGen\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n",
    "\n",
    "    # 4. Komponen SchemaGen\n",
    "    schema_gen = SchemaGen(statistics=statistics_gen.outputs[\"statistics\"])\n",
    "\n",
    "    # 5. Komponen ExampleValidator\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        schema=schema_gen.outputs[\"schema\"]\n",
    "    )\n",
    "\n",
    "    # 6. Komponen Transform\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        module_file=os.path.abspath(config[\"transform_module\"])\n",
    "    )\n",
    "\n",
    "    # Validasi path module\n",
    "    assert os.path.exists(config[\"transform_module\"]), \"Transform module file not found!\"\n",
    "\n",
    "    # 7. Komponen Tuner\n",
    "    tuner = Tuner(\n",
    "        module_file=os.path.abspath(config[\"tuner_module\"]),\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        transform_graph=transform.outputs[\"transform_graph\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        train_args=trainer_pb2.TrainArgs(splits=[\"train\"], num_steps=config[\"training_steps\"]),\n",
    "        eval_args=trainer_pb2.EvalArgs(splits=[\"eval\"], num_steps=config[\"eval_steps\"])\n",
    "    )\n",
    "\n",
    "    assert os.path.exists(config[\"tuner_module\"]), \"Tuner module file not found!\"\n",
    "\n",
    "    # 8. Komponen Trainer\n",
    "    trainer = Trainer(\n",
    "        module_file=os.path.abspath(config[\"training_module\"]),\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        transform_graph=transform.outputs[\"transform_graph\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        hyperparameters=tuner.outputs[\"best_hyperparameters\"],\n",
    "        train_args=trainer_pb2.TrainArgs(splits=[\"train\"], num_steps=config[\"training_steps\"]),\n",
    "        eval_args=trainer_pb2.EvalArgs(splits=[\"eval\"], num_steps=config[\"eval_steps\"])\n",
    "    )\n",
    "\n",
    "    assert os.path.exists(config[\"training_module\"]), \"Training module file not found!\"\n",
    "\n",
    "    # 9. Komponen Model Resolver\n",
    "    model_resolver = Resolver(\n",
    "        strategy_class=LatestBlessedModelStrategy,\n",
    "        model=Channel(type=Model),\n",
    "        model_blessing=Channel(type=ModelBlessing)\n",
    "    ).with_id(\"Latest_blessed_model_resolver\")\n",
    "\n",
    "    # 10. Konfigurasi Evaluator\n",
    "    metrics_specs = [\n",
    "        tfma.MetricsSpec(metrics=[\n",
    "            tfma.MetricConfig(class_name=\"AUC\"),\n",
    "            tfma.MetricConfig(class_name=\"Precision\"),\n",
    "            tfma.MetricConfig(class_name=\"Recall\"),\n",
    "            tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "            tfma.MetricConfig(\n",
    "                class_name=\"CategoricalAccuracy\",\n",
    "                threshold=tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(lower_bound={\"value\": 0.9}),\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                        absolute={\"value\": 0.0001}\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=\"Anxiety Category Encoded\")],\n",
    "        slicing_specs=[tfma.SlicingSpec()],\n",
    "        metrics_specs=metrics_specs\n",
    "    )\n",
    "\n",
    "    evaluator = Evaluator(\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        baseline_model=model_resolver.outputs[\"model\"],\n",
    "        eval_config=eval_config\n",
    "    )\n",
    "\n",
    "    # 11. Komponen Pusher\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        model_blessing=evaluator.outputs[\"blessing\"],\n",
    "        push_destination=pusher_pb2.PushDestination(\n",
    "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "                base_directory=config[\"serving_model_dir\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mengembalikan tuple komponen untuk pipeline\n",
    "    return (\n",
    "        example_gen, statistics_gen, schema_gen, example_validator,\n",
    "        transform, tuner, trainer, model_resolver, evaluator, pusher\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                    int64\n",
      "Gender                                object\n",
      "Occupation                            object\n",
      "Sleep Hours                          float64\n",
      "Physical Activity (hrs/week)         float64\n",
      "Caffeine Intake (mg/day)               int64\n",
      "Alcohol Consumption (drinks/week)      int64\n",
      "Smoking                               object\n",
      "Family History of Anxiety             object\n",
      "Stress Level (1-10)                    int64\n",
      "Heart Rate (bpm during attack)         int64\n",
      "Breathing Rate (breaths/min)           int64\n",
      "Sweating Level (1-5)                   int64\n",
      "Dizziness                             object\n",
      "Medication                            object\n",
      "Therapy Sessions (per month)           int64\n",
      "Recent Major Life Event               object\n",
      "Diet Quality (1-10)                    int64\n",
      "Anxiety Category                      object\n",
      "Anxiety Category Encoded               int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Misalkan df adalah DataFrame dengan data mentah\n",
    "print(data_check.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom Age bertipe data numerik\n",
      "Kolom Sleep Hours bertipe data numerik\n",
      "Kolom Physical Activity (hrs/week) bertipe data numerik\n",
      "Kolom Caffeine Intake (mg/day) bertipe data numerik\n",
      "Kolom Alcohol Consumption (drinks/week) bertipe data numerik\n",
      "Kolom Stress Level (1-10) bertipe data numerik\n",
      "Kolom Heart Rate (bpm during attack) bertipe data numerik\n",
      "Kolom Breathing Rate (breaths/min) bertipe data numerik\n",
      "Kolom Sweating Level (1-5) bertipe data numerik\n",
      "Kolom Therapy Sessions (per month) bertipe data numerik\n",
      "Kolom Diet Quality (1-10) bertipe data numerik\n"
     ]
    }
   ],
   "source": [
    "for kolom in data_check.columns:\n",
    "    if data_check[kolom].dtype == 'int64' or data_check[kolom].dtype == 'float64':\n",
    "        print(f\"Kolom {kolom} bertipe data numerik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Transform: Modul Transformasi Fitur untuk Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_transform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRANSFORM_MODULE_FILE}\n",
    "\"\"\"\n",
    "anxiety_transform.py\n",
    "\n",
    "Modul ini menangani transformasi fitur untuk preprocessing data\n",
    "menggunakan TensorFlow Transform (TFT).\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "# Daftar numerical fitur pada dataset\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"Age\",\n",
    "    \"Sleep Hours\",\n",
    "    \"Physical Activity (hrs/week)\",\n",
    "    \"Caffeine Intake (mg/day)\",\n",
    "    \"Alcohol Consumption (drinks/week)\",\n",
    "    \"Stress Level (1-10)\",\n",
    "    \"Heart Rate (bpm during attack)\",\n",
    "    \"Breathing Rate (breaths/min)\",\n",
    "    \"Sweating Level (1-5)\",\n",
    "    \"Therapy Sessions (per month)\",\n",
    "    \"Diet Quality (1-10)\",\n",
    "]\n",
    "\n",
    "# Daftar categorical fitur pada dataset\n",
    "CATEGORICAL_FEATURES = [\n",
    "    \"Gender\",\n",
    "    \"Occupation\",\n",
    "    \"Smoking\",\n",
    "    \"Family History of Anxiety\",\n",
    "    \"Dizziness\",\n",
    "    \"Medication\",\n",
    "    \"Recent Major Life Event\",\n",
    "]\n",
    "\n",
    "# Label key\n",
    "LABEL_KEY = \"Anxiety Category Encoded\"\n",
    "\n",
    "def transformed_name(key):\n",
    "    \"\"\"\n",
    "    Menambahkan suffix '_xf' untuk fitur yang telah ditransformasikan.\n",
    "\n",
    "    Args:\n",
    "        key (str): Nama fitur sebelum transformasi.\n",
    "\n",
    "    Returns:\n",
    "        str: Nama fitur setelah transformasi.\n",
    "    \"\"\"\n",
    "    return f\"{key}_xf\"\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"\n",
    "    Melakukan preprocessing pada fitur input.\n",
    "\n",
    "    Args:\n",
    "        inputs (dict): Dictionary dari feature keys ke raw features.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary dari feature keys ke transformed features.\n",
    "    \"\"\"\n",
    "    outputs = {}\n",
    "\n",
    "    # 1Ô∏è‚É£ Encoding fitur kategorikal menjadi integer (menggunakan vocabulary encoding)\n",
    "    encoded_categorical_features = {\n",
    "        feature: tft.compute_and_apply_vocabulary(\n",
    "            tf.strings.strip(tf.strings.lower(inputs[feature]))\n",
    "        )\n",
    "        for feature in CATEGORICAL_FEATURES\n",
    "        if feature in inputs\n",
    "    }\n",
    "\n",
    "    # 2Ô∏è‚É£ Gabungkan semua fitur numerik dan fitur kategorikal yang telah dienkode\n",
    "    all_numeric_features = {**encoded_categorical_features}\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        if feature in inputs:\n",
    "            all_numeric_features[feature] = tf.cast(inputs[feature], tf.float32)\n",
    "\n",
    "    # 3Ô∏è‚É£ Normalisasi semua fitur numerik agar berada dalam rentang [0,1]\n",
    "    for feature, tensor in all_numeric_features.items():\n",
    "        outputs[transformed_name(feature)] = tft.scale_to_0_1(tensor)\n",
    "\n",
    "    # 4Ô∏è‚É£ Transformasi label target menjadi integer\n",
    "    if LABEL_KEY in inputs:\n",
    "        outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Moderate Anxiety       3680\n",
       "Severe Anxiety         3602\n",
       "Mild Anxiety           3531\n",
       "Panic Level Anxiety    1187\n",
       "Name: Anxiety Category, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_check[\"Anxiety Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Tuner: Modul Tuning Hyperparameter Model dengan Keras Tuner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_tuner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TUNER_MODULE_FILE}\n",
    "\"\"\"\n",
    "anxiety_tuner.py\n",
    "\n",
    "Modul ini digunakan untuk melakukan tuning hyperparameter model menggunakan Keras Tuner.\n",
    "\"\"\"\n",
    "\n",
    "# Import library\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorflow_transform as tft\n",
    "from tfx.v1.components import TunerFnResult\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from anxiety_trainer import NUMERICAL_FEATURES, CATEGORICAL_FEATURES, transformed_name, input_fn\n",
    "\n",
    "def model_builder(hyperparameters):\n",
    "    \"\"\"\n",
    "    Membuat model Keras dengan hyperparameter yang akan dituning.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters (kt.HyperParameters): Hyperparameters yang akan digunakan untuk tuning.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Model Keras yang dikompilasi.\n",
    "    \"\"\"\n",
    "\n",
    "    input_features = [\n",
    "        tf.keras.Input(shape=(1,), name=transformed_name(key))\n",
    "        for key in NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "    ]\n",
    "\n",
    "    concatenate = tf.keras.layers.concatenate(input_features)\n",
    "\n",
    "    # Hyperparameter yang lebih luas untuk optimasi lebih baik\n",
    "    unit_1 = hyperparameters.Int('unit_1', min_value=128, max_value=512, step=64)\n",
    "    dropout_1 = hyperparameters.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    unit_2 = hyperparameters.Int('unit_2', min_value=64, max_value=256, step=32)\n",
    "    dropout_2 = hyperparameters.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    unit_3 = hyperparameters.Int('unit_3', min_value=32, max_value=128, step=32)\n",
    "    dropout_3 = hyperparameters.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    learning_rate = hyperparameters.Choice('learning_rate', [0.0001, 0.0005, 0.001, 0.005])\n",
    "\n",
    "    # Membangun arsitektur model\n",
    "    deep = tf.keras.layers.Dense(unit_1, activation=\"relu\")(concatenate)\n",
    "    deep = tf.keras.layers.Dropout(dropout_1)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_2, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_2)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_3, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_3)(deep)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(deep)  # 4 kelas untuk klasifikasi\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "\n",
    "    # Kompilasi model dengan optimizer yang dituning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def tuner_fn(fn_args: FnArgs):\n",
    "    \"\"\"\n",
    "    Melakukan tuning hyperparameter menggunakan Keras Tuner.\n",
    "\n",
    "    Args:\n",
    "        fn_args (FnArgs): Argumen fungsi dari TFX yang berisi informasi data & model.\n",
    "\n",
    "    Returns:\n",
    "        TunerFnResult: Objek hasil tuning dari TFX.\n",
    "    \"\"\"\n",
    "\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    # Ambil dataset pelatihan dan evaluasi\n",
    "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, batch_size=32)\n",
    "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, batch_size=32)\n",
    "\n",
    "    # Inisialisasi RandomSearch tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_builder,\n",
    "        objective='val_sparse_categorical_accuracy',  # Optimasi berdasarkan akurasi validasi\n",
    "        max_trials=10,\n",
    "        executions_per_trial=2,\n",
    "        directory=fn_args.working_dir,\n",
    "        project_name='anxiety_severity_tuner'\n",
    "    )\n",
    "\n",
    "    return TunerFnResult(\n",
    "        tuner=tuner,\n",
    "        fit_kwargs={\n",
    "            \"x\": train_dataset,\n",
    "            \"validation_data\": eval_dataset,\n",
    "            \"steps_per_epoch\": fn_args.train_steps,\n",
    "            \"validation_steps\": fn_args.eval_steps,\n",
    "            \"epochs\": 8\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Trainer: Modul Pelatihan dan Penyajian Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_MODULE_FILE}\n",
    "\"\"\"\n",
    "anxiety_trainer.py\n",
    "\n",
    "Modul ini berisi fungsi pelatihan model Machine Learning untuk klasifikasi tingkat kecemasan.\n",
    "\"\"\"\n",
    "\n",
    "# Import library\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from anxiety_transform import (\n",
    "    LABEL_KEY,\n",
    "    NUMERICAL_FEATURES,\n",
    "    CATEGORICAL_FEATURES,\n",
    "    transformed_name,\n",
    ")\n",
    "\n",
    "def get_model(hyperparameters, show_summary=True):\n",
    "    \"\"\"\n",
    "    Membuat model dengan hyperparameter terbaik dari tuner.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters (dict): Dictionary berisi nilai hyperparameter.\n",
    "        show_summary (bool): Menampilkan summary model jika True.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Model Keras yang telah dikompilasi.\n",
    "    \"\"\"\n",
    "\n",
    "    input_features = [\n",
    "        tf.keras.Input(shape=(1,), name=transformed_name(feature))\n",
    "        for feature in NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "    ]\n",
    "\n",
    "    concatenate = tf.keras.layers.concatenate(input_features)\n",
    "\n",
    "    # Ambil hyperparameter terbaik dari tuner\n",
    "    unit_1 = hyperparameters.get('unit_1', 128)\n",
    "    dropout_1 = hyperparameters.get('dropout_1', 0.2)\n",
    "    unit_2 = hyperparameters.get('unit_2', 64)\n",
    "    dropout_2 = hyperparameters.get('dropout_2', 0.2)\n",
    "    unit_3 = hyperparameters.get('unit_3', 32)\n",
    "    dropout_3 = hyperparameters.get('dropout_3', 0.2)\n",
    "    learning_rate = hyperparameters.get('learning_rate', 0.001)\n",
    "\n",
    "    # Lapisan Dense berdasarkan hyperparameter yang dituning\n",
    "    deep = tf.keras.layers.Dense(unit_1, activation=\"relu\")(concatenate)\n",
    "    deep = tf.keras.layers.Dropout(dropout_1)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_2, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_2)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_3, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_3)(deep)\n",
    "\n",
    "    # Output layer untuk klasifikasi multi-kelas\n",
    "    outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(deep)\n",
    "\n",
    "    # Buat model\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "\n",
    "    # Kompilasi model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def gzip_reader_fn(filenames):\n",
    "    \"\"\"Loads compressed data\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "\n",
    "def get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        feature_spec.pop(LABEL_KEY)\n",
    "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
    "    \"\"\"\n",
    "    Generates features and labels for tuning/training.\n",
    "\n",
    "    Args:\n",
    "        file_pattern (str): Pola file untuk dataset.\n",
    "        tf_transform_output: Output dari transformasi fitur.\n",
    "        batch_size (int): Ukuran batch.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Dataset dalam format TensorFlow.\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=gzip_reader_fn,\n",
    "        label_key=transformed_name(LABEL_KEY),\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def run_fn(fn_args):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melatih model berdasarkan hasil tuning dari tuner.\n",
    "\n",
    "    Args:\n",
    "        fn_args: Argumen dari TFX yang berisi informasi data & model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hasil transformasi fitur\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "    # Ambil hyperparameters terbaik dari tuner\n",
    "    hyperparameters = fn_args.hyperparameters\n",
    "\n",
    "    # Ambil dataset pelatihan dan evaluasi\n",
    "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, batch_size=64)\n",
    "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, batch_size=64)\n",
    "\n",
    "    # Buat model dengan hyperparameter terbaik\n",
    "    model = get_model(hyperparameters)\n",
    "\n",
    "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=\"batch\")\n",
    "\n",
    "    # Tambahkan callback untuk optimalisasi training\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=8, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001\n",
    "    )\n",
    "\n",
    "    # Latih model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        callbacks=[tensorboard_callback, early_stopping, reduce_lr],\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    # Simpan model untuk serving\n",
    "    signatures = {\n",
    "        \"serving_default\": get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    model.save(fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Inisialisasi Pipeline Lokal dengan Apache Beam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_local_pipeline(\n",
    "    components, pipeline_root: Text\n",
    ") -> tfx_pipeline.Pipeline:  # Use the aliased name here\n",
    "    \n",
    "    logging.info(f\"Pipeline root set to: {pipeline_root}\")\n",
    "\n",
    "    \n",
    "    return tfx_pipeline.Pipeline(  # Use the aliased name here\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=pipeline_root,\n",
    "        components=components,\n",
    "        enable_cache=True,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
    "            METADATA_PATH\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. Menjalankan Pipeline Lokal Menggunakan Apache Beam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 27s]\n",
      "val_sparse_categorical_accuracy: 0.2943124920129776\n",
      "\n",
      "Best val_sparse_categorical_accuracy So Far: 0.3099374920129776\n",
      "Total elapsed time: 00h 14m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Int', 'config': {'name': 'unit_1', 'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 64, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_1', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'unit_2', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_2', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'unit_3', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_3', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.0005, 0.001, 0.005], 'ordered': True}}], 'values': {'unit_1': 448, 'dropout_1': 0.1, 'unit_2': 256, 'dropout_2': 0.4, 'unit_3': 64, 'dropout_3': 0.2, 'learning_rate': 0.0005}}\n",
      "INFO:absl:Best Hyperparameters are written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Tuner\\best_hyperparameters\\108\\best_hyperparameters.txt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 108 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'best_hyperparameters': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Tuner\\\\best_hyperparameters\\\\108\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Tuner:best_hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 108\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Tuner is finished.\n",
      "INFO:absl:node Trainer is running.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Tuner\\.system\\executor_execution\\108\\.temp\\108\\anxiety_severity_tuner\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000023210B1D4F0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 448\n",
      "dropout_1: 0.1\n",
      "unit_2: 256\n",
      "dropout_2: 0.4\n",
      "unit_3: 64\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0005\n",
      "Score: 0.3099374920129776\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 384\n",
      "dropout_1: 0.1\n",
      "unit_2: 96\n",
      "dropout_2: 0.4\n",
      "unit_3: 96\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.005\n",
      "Score: 0.30924999713897705\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 128\n",
      "dropout_1: 0.4\n",
      "unit_2: 160\n",
      "dropout_2: 0.30000000000000004\n",
      "unit_3: 64\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0005\n",
      "Score: 0.3085625022649765\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 320\n",
      "dropout_1: 0.2\n",
      "unit_2: 192\n",
      "dropout_2: 0.2\n",
      "unit_3: 128\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.3062499910593033\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 512\n",
      "dropout_1: 0.4\n",
      "unit_2: 64\n",
      "dropout_2: 0.2\n",
      "unit_3: 32\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0005\n",
      "Score: 0.3061874955892563\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 384\n",
      "dropout_1: 0.2\n",
      "unit_2: 160\n",
      "dropout_2: 0.4\n",
      "unit_3: 32\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0005\n",
      "Score: 0.304749995470047\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 256\n",
      "dropout_1: 0.2\n",
      "unit_2: 128\n",
      "dropout_2: 0.4\n",
      "unit_3: 96\n",
      "dropout_3: 0.5\n",
      "learning_rate: 0.001\n",
      "Score: 0.3044374883174896\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 256\n",
      "dropout_1: 0.4\n",
      "unit_2: 224\n",
      "dropout_2: 0.2\n",
      "unit_3: 64\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.29749999940395355\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 192\n",
      "dropout_1: 0.1\n",
      "unit_2: 256\n",
      "dropout_2: 0.5\n",
      "unit_3: 32\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.0005\n",
      "Score: 0.29637500643730164\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 128\n",
      "dropout_1: 0.4\n",
      "unit_2: 192\n",
      "dropout_2: 0.2\n",
      "unit_3: 128\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "Score: 0.2943124920129776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 250,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 109\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=109, input_dict={'schema': [Artifact(artifact: id: 171\n",
      "type_id: 20\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\SchemaGen\\\\schema\\\\105\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:SchemaGen:schema:0\"\n",
      "create_time_since_epoch: 1739126706415\n",
      "last_update_time_since_epoch: 1739126706415\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'hyperparameters': [Artifact(artifact: id: 181\n",
      "type_id: 27\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Tuner\\\\best_hyperparameters\\\\108\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Tuner:best_hyperparameters:0\"\n",
      "create_time_since_epoch: 1739127639672\n",
      "last_update_time_since_epoch: 1739127639672\n",
      ", artifact_type: id: 27\n",
      "name: \"HyperParameters\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 174\n",
      "type_id: 24\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Transform\\\\transform_graph\\\\107\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Transform:transform_graph:0\"\n",
      "create_time_since_epoch: 1739126760993\n",
      "last_update_time_since_epoch: 1739126760993\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 176\n",
      "type_id: 15\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Transform\\\\transformed_examples\\\\107\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Transform:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Transform:transformed_examples:0\"\n",
      "create_time_since_epoch: 1739126760993\n",
      "last_update_time_since_epoch: 1739126760993\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model_run\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'module_path': 'anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'eval_args': '{\\n  \"num_steps\": 250,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'custom_config': 'null'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\executor_execution\\\\109\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\stateful_working_dir\\\\20250210-014456.003231', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\executor_execution\\\\109\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 250,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250210-014456.003231')\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'module_path': 'anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'eval_args': '{\\n  \"num_steps\": 250,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'custom_config': 'null'} 'run_fn'\n",
      "INFO:absl:Installing 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['c:\\\\Users\\\\rendi\\\\anaconda3\\\\envs\\\\tfx-beam\\\\python.exe', '-m', 'pip', 'install', '--target', 'C:\\\\Users\\\\rendi\\\\AppData\\\\Local\\\\Temp\\\\tmptn23ypj0', 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl']\n",
      "INFO:absl:Successfully installed 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+f9ae9800482682500a84345fb4957391e7d06a38ea5f98aaf118449a0542dcc1-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Sleep Hours_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Physical Activity (hrs/week)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Caffeine Intake (mg/day)_xf (I  [(None, 1)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Alcohol Consumption (drinks/we  [(None, 1)]         0           []                               \n",
      " ek)_xf (InputLayer)                                                                              \n",
      "                                                                                                  \n",
      " Stress Level (1-10)_xf (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Heart Rate (bpm during attack)  [(None, 1)]         0           []                               \n",
      " _xf (InputLayer)                                                                                 \n",
      "                                                                                                  \n",
      " Breathing Rate (breaths/min)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Sweating Level (1-5)_xf (Input  [(None, 1)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " Therapy Sessions (per month)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Diet Quality (1-10)_xf (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Gender_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Occupation_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Smoking_xf (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Family History of Anxiety_xf (  [(None, 1)]         0           []                               \n",
      " InputLayer)                                                                                      \n",
      "                                                                                                  \n",
      " Dizziness_xf (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Medication_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Recent Major Life Event_xf (In  [(None, 1)]         0           []                               \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 18)           0           ['Age_xf[0][0]',                 \n",
      "                                                                  'Sleep Hours_xf[0][0]',         \n",
      "                                                                  'Physical Activity (hrs/week)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Caffeine Intake (mg/day)_xf[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'Alcohol Consumption (drinks/wee\n",
      "                                                                 k)_xf[0][0]',                    \n",
      "                                                                  'Stress Level (1-10)_xf[0][0]', \n",
      "                                                                  'Heart Rate (bpm during attack)_\n",
      "                                                                 xf[0][0]',                       \n",
      "                                                                  'Breathing Rate (breaths/min)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Sweating Level (1-5)_xf[0][0]',\n",
      "                                                                  'Therapy Sessions (per month)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Diet Quality (1-10)_xf[0][0]', \n",
      "                                                                  'Gender_xf[0][0]',              \n",
      "                                                                  'Occupation_xf[0][0]',          \n",
      "                                                                  'Smoking_xf[0][0]',             \n",
      "                                                                  'Family History of Anxiety_xf[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'Dizziness_xf[0][0]',           \n",
      "                                                                  'Medication_xf[0][0]',          \n",
      "                                                                  'Recent Major Life Event_xf[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          2432        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            132         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,900\n",
      "Trainable params: 12,900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 6s 5ms/step - loss: 1.3170 - sparse_categorical_accuracy: 0.3070 - val_loss: 1.3166 - val_sparse_categorical_accuracy: 0.2722 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3091 - sparse_categorical_accuracy: 0.3198 - val_loss: 1.3237 - val_sparse_categorical_accuracy: 0.2962 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3026 - sparse_categorical_accuracy: 0.3324 - val_loss: 1.3316 - val_sparse_categorical_accuracy: 0.2775 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2926 - sparse_categorical_accuracy: 0.3474 - val_loss: 1.3365 - val_sparse_categorical_accuracy: 0.2823 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2750 - sparse_categorical_accuracy: 0.3697 - val_loss: 1.3507 - val_sparse_categorical_accuracy: 0.2957 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2640 - sparse_categorical_accuracy: 0.3779 - val_loss: 1.3645 - val_sparse_categorical_accuracy: 0.2733 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2549 - sparse_categorical_accuracy: 0.3878 - val_loss: 1.3684 - val_sparse_categorical_accuracy: 0.2786 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2435 - sparse_categorical_accuracy: 0.3978 - val_loss: 1.3798 - val_sparse_categorical_accuracy: 0.2693 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2379 - sparse_categorical_accuracy: 0.4037 - val_loss: 1.3807 - val_sparse_categorical_accuracy: 0.2649 - lr: 2.5000e-04\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\109\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\109\\Format-Serving\\assets\n",
      "INFO:absl:Training complete. Model written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\109\\Format-Serving. ModelRun written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model_run\\109\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 109 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model_run\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 109\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Trainer is finished.\n",
      "INFO:absl:node Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"CategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"Anxiety Category Encoded\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 110\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=110, input_dict={'baseline_model': [], 'model': [Artifact(artifact: id: 182\n",
      "type_id: 29\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "create_time_since_epoch: 1739127692533\n",
      "last_update_time_since_epoch: 1739127692533\n",
      ", artifact_type: id: 29\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'examples': [Artifact(artifact: id: 169\n",
      "type_id: 15\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\CsvExampleGen\\\\examples\\\\102\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:976219,xor_checksum:1739126691,sum_checksum:1739126691\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:CsvExampleGen:examples:0\"\n",
      "create_time_since_epoch: 1739126702380\n",
      "last_update_time_since_epoch: 1739126702380\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\110\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\evaluation\\\\110\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Evaluator:evaluation:0\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}), exec_properties={'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\executor_execution\\\\110\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\stateful_working_dir\\\\20250210-014456.003231', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\executor_execution\\\\110\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"CategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"Anxiety Category Encoded\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250210-014456.003231')\n",
      "INFO:absl:udf_utils.get_fn {'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'} 'custom_eval_shared_model'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\109\\Format-Serving as  model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000231E189B100> and <keras.engine.input_layer.InputLayer object at 0x0000023210B2E220>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000231E189B100> and <keras.engine.input_layer.InputLayer object at 0x0000023210B2E220>).\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "INFO:absl:udf_utils.get_fn {'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null'} 'custom_extractors'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E0BC7AF0> and <keras.engine.input_layer.InputLayer object at 0x00000231FFA76D00>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E0BC7AF0> and <keras.engine.input_layer.InputLayer object at 0x00000231FFA76D00>).\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.9 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E0827F70> and <keras.engine.input_layer.InputLayer object at 0x00000231E0F6E520>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E0827F70> and <keras.engine.input_layer.InputLayer object at 0x00000231E0F6E520>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E19BD3D0> and <keras.engine.input_layer.InputLayer object at 0x00000230E07D0370>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E19BD3D0> and <keras.engine.input_layer.InputLayer object at 0x00000230E07D0370>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E2F02DF0> and <keras.engine.input_layer.InputLayer object at 0x00000231E166EC10>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000230E2F02DF0> and <keras.engine.input_layer.InputLayer object at 0x00000231E166EC10>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000231E1758310> and <keras.engine.input_layer.InputLayer object at 0x00000231DFEA3F10>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000231E1758310> and <keras.engine.input_layer.InputLayer object at 0x00000231DFEA3F10>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002320E5AA790> and <keras.engine.input_layer.InputLayer object at 0x00000232100610A0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002320E5AA790> and <keras.engine.input_layer.InputLayer object at 0x00000232100610A0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002321099BC40> and <keras.engine.input_layer.InputLayer object at 0x000002320FFEF280>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002321099BC40> and <keras.engine.input_layer.InputLayer object at 0x000002320FFEF280>).\n",
      "INFO:absl:Evaluation complete. Results written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\evaluation\\110.\n",
      "INFO:absl:Checking validation results.\n",
      "INFO:absl:Blessing result False written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\blessing\\110.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 110 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\110\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\evaluation\\\\110\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Evaluator:evaluation:0\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}) for execution 110\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Evaluator is finished.\n",
      "INFO:absl:node Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model_dir\\\\\\\\anxiety-model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 111\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=111, input_dict={'model': [Artifact(artifact: id: 182\n",
      "type_id: 29\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\109\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Trainer:model:0\"\n",
      "create_time_since_epoch: 1739127692533\n",
      "last_update_time_since_epoch: 1739127692533\n",
      ", artifact_type: id: 29\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_blessing': [Artifact(artifact: id: 184\n",
      "type_id: 33\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\110\"\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\109\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 182\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Evaluator:blessing:0\"\n",
      "create_time_since_epoch: 1739127704855\n",
      "last_update_time_since_epoch: 1739127704855\n",
      ", artifact_type: id: 33\n",
      "name: \"ModelBlessing\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\pushed_model\\\\111\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model_dir\\\\\\\\anxiety-model\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\executor_execution\\\\111\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\stateful_working_dir\\\\20250210-014456.003231', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\executor_execution\\\\111\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250210-014456.003231\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250210-014456.003231\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model_dir\\\\\\\\anxiety-model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250210-014456.003231')\n",
      "INFO:absl:Model on RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\blessing\\110 was not blessed by model validation\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 111 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\pushed_model\\\\111\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250210-014456.003231:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250210-014456.003231:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 111\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "from modules.components import init_components\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "config = {\n",
    "    \"DATA_ROOT\": DATA_ROOT,\n",
    "    \"training_module\": TRAINER_MODULE_FILE,\n",
    "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
    "    \"tuner_module\": TUNER_MODULE_FILE,\n",
    "    \"training_steps\": 1000,\n",
    "    \"eval_steps\": 250,\n",
    "    \"serving_model_dir\": SERVING_MODEL_DIR,\n",
    "}\n",
    "\n",
    "components = init_components(config)\n",
    "\n",
    "pipeline = init_local_pipeline(components, PIPELINE_ROOT)\n",
    "BeamDagRunner().run(pipeline=pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx-beam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
