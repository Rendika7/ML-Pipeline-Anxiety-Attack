{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengembangan dan Pengoperasian Sistem Machine Learning untuk Prediksi Keparahan Serangan Kecemasan\n",
    "\n",
    "- Nama: `Rendika Nurhartanto Suharto`\n",
    "- Username dicoding: ```RENDIKA NURHARTANTO SUHARTO```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import Library and Dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n proyek-akhir-mlops python=3.9.15 -y\n",
    "# conda activate proyek-akhir-mlops\n",
    "# pip install -r requirements.txt\n",
    "# pip install autopep8 pylint\n",
    "\n",
    "# conda create -n tfx-beam python=3.8.18 -y\n",
    "# conda activate tfx-beam\n",
    "# pip install -r requirements-2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "from typing import Text\n",
    "from absl import logging  # type: ignore\n",
    "from tfx.orchestration import metadata  # type: ignore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tfx.orchestration import pipeline as tfx_pipeline  # type: ignore\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Set Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan set variabel seperti pipeline name, path untuk menyimpan output, path module, dan banyak lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline and schema names\n",
    "PIPELINE_NAME = \"anxiety-pipeline\"  # Name of the main pipeline\n",
    "SCHEMA_PIPELINE_NAME = \"anxiety-tfdv-schema\"  # Name of the schema pipeline\n",
    "MODEL_NAME = \"anxiety-model\" # Name of the saved model\n",
    "\n",
    "# Directory for storing generated artifacts\n",
    "PIPELINE_ROOT = os.path.join('RENDIKA_NURHARTANTO_SUHARTO-pipeline', PIPELINE_NAME)  # Root directory for pipeline artifacts\n",
    "\n",
    "# Path to SQLite DB file for MLMD storage\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.sqlite')  # Path to metadata database\n",
    "\n",
    "# Output directory for exporting trained models\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model_dir', MODEL_NAME)  # Directory for saving trained models\n",
    "\n",
    "# Pipeline inputs\n",
    "DATA_ROOT = \"data\"  # Root directory for input data\n",
    "COMPONENTS_MODULE_FILE = \"modules/components.py\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/anxiety_transform.py\"  # Transformation logic module\n",
    "TRAINER_MODULE_FILE = \"modules/anxiety_trainer.py\"  # Model training logic module\n",
    "TUNER_MODULE_FILE = \"modules/anxiety_tuner.py\"  # Hyperparameter tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subdirectories\n",
    "project_root = \"C:/Users/rendi/ITTS DATA SCIENCE/Semester 8\\MLOps - Dicoding Bonus Course/2. Proyek Akhir - Proyek Pengembangan dan Pengoperasian Sistem Machine Learning\"\n",
    "modules_dir = os.path.join(project_root, \"modules\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(modules_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Checking and Processing Dataset with Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Anxiety Attack : Factors, Symptoms, and Severity\n",
    "\n",
    "**Data Format**: CSV (Comma-Separated Values)\n",
    "\n",
    "**Size**: 12,000+ records\n",
    "\n",
    "**Usability in Kaggle**: 10.00\n",
    "\n",
    "**Description**: This dataset contains over **12,000 records** detailing various factors related to anxiety attacks, including demographics, lifestyle habits, stress levels, and physiological responses. It is designed for **data analysis**, **machine learning**, and **mental health research** to explore patterns, triggers, and potential correlations in anxiety disorders.\n",
    "\n",
    "**Key Features**:\n",
    "\n",
    "üßë‚Äçü§ù‚Äçüßë Demographics: Age, Gender, Occupation\n",
    "\n",
    "üåô Lifestyle Factors: Sleep, Physical Activity, Diet, Caffeine & Alcohol Intake\n",
    "\n",
    "üíì Health Indicators: Heart Rate, Breathing Rate, Sweating, Dizziness\n",
    "\n",
    "üß† Psychological Factors: Stress Level, Family History, Therapy & Medication\n",
    "\n",
    "‚ö†Ô∏è Anxiety Attack Severity: Scale from 1 to 10\n",
    "\n",
    "**Feature Explaination**:\n",
    "\n",
    "| **Feature**                  | **Description**                                                            |\n",
    "| ----------------------------: | -------------------------------------------------------------------------- |\n",
    "| `ID`                         | Unique identifier for each record                                          |\n",
    "| `Age`                        | Age of the individual (18 to 64 years)                                     |\n",
    "| `Gender`                     | Gender of the individual (Male, Female, Other)                             |\n",
    "| `Occupation`                 | Job role of the individual                                                 |\n",
    "| `Sleep Hours`                | Daily sleep duration (in hours)                                            |\n",
    "| `Physical Activity`          | Weekly exercise duration (in hours)                                        |\n",
    "| `Caffeine Intake`            | Daily caffeine intake (in mg)                                              |\n",
    "| `Alcohol Consumption`        | Weekly alcohol consumption (in drinks)                                     |\n",
    "| `Smoking`                    | Whether the individual smokes (Yes/No)                                      |\n",
    "| `Family History of Anxiety`  | Whether the individual has a family history of anxiety (Yes/No)            |\n",
    "| `Stress Level`               | Stress level (scale from 1 to 10)                                          |\n",
    "| `Heart Rate`                 | Heart rate (bpm) during an anxiety attack                                  |\n",
    "| `Breathing Rate`             | Breathing rate (breaths per minute) during an anxiety attack               |\n",
    "| `Sweating Level`             | Sweating level (scale from 1 to 5)                                         |\n",
    "| `Dizziness`                  | Whether dizziness was experienced during the attack (Yes/No)               |\n",
    "| `Medication`                 | Whether the individual is on medication for anxiety (Yes/No)               |\n",
    "| `Therapy Sessions`           | Number of therapy sessions attended per month                              |\n",
    "| `Recent Major Life Event`    | Whether the individual has experienced a recent major life event (Yes/No)  |\n",
    "| `Diet Quality`               | Quality of the individual's diet (scale from 1 to 10)                      |\n",
    "| `Severity of Anxiety Attack` | Severity of the anxiety attack (scale from 1 to 10)                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset\n",
    "data_check = pd.read_csv(\"anxiety_attack_dataset.csv\").drop(columns = \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Physical Activity (hrs/week)</th>\n",
       "      <th>Caffeine Intake (mg/day)</th>\n",
       "      <th>Alcohol Consumption (drinks/week)</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Family History of Anxiety</th>\n",
       "      <th>Stress Level (1-10)</th>\n",
       "      <th>Heart Rate (bpm during attack)</th>\n",
       "      <th>Breathing Rate (breaths/min)</th>\n",
       "      <th>Sweating Level (1-5)</th>\n",
       "      <th>Dizziness</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Therapy Sessions (per month)</th>\n",
       "      <th>Recent Major Life Event</th>\n",
       "      <th>Diet Quality (1-10)</th>\n",
       "      <th>Severity of Anxiety Attack (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467</td>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>471</td>\n",
       "      <td>16</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>Student</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>364</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender Occupation  Sleep Hours  Physical Activity (hrs/week)  \\\n",
       "0   56  Female      Other          9.6                           8.3   \n",
       "1   46    Male    Teacher          6.4                           7.3   \n",
       "2   32  Female     Doctor          6.9                           1.0   \n",
       "3   60    Male     Doctor          9.2                           3.7   \n",
       "4   25    Male    Student          9.2                           2.5   \n",
       "\n",
       "   Caffeine Intake (mg/day)  Alcohol Consumption (drinks/week) Smoking  \\\n",
       "0                       175                                  6      No   \n",
       "1                        97                                  6      No   \n",
       "2                       467                                 14      No   \n",
       "3                       471                                 16      No   \n",
       "4                       364                                  2      No   \n",
       "\n",
       "  Family History of Anxiety  Stress Level (1-10)  \\\n",
       "0                        No                    4   \n",
       "1                        No                    3   \n",
       "2                        No                    2   \n",
       "3                       Yes                    6   \n",
       "4                       Yes                    7   \n",
       "\n",
       "   Heart Rate (bpm during attack)  Breathing Rate (breaths/min)  \\\n",
       "0                             145                            33   \n",
       "1                             143                            18   \n",
       "2                              60                            34   \n",
       "3                              94                            19   \n",
       "4                             152                            15   \n",
       "\n",
       "   Sweating Level (1-5) Dizziness Medication  Therapy Sessions (per month)  \\\n",
       "0                     3        No         No                             4   \n",
       "1                     5       Yes         No                             0   \n",
       "2                     1        No         No                             7   \n",
       "3                     1        No        Yes                             4   \n",
       "4                     4        No        Yes                             0   \n",
       "\n",
       "  Recent Major Life Event  Diet Quality (1-10)  \\\n",
       "0                     Yes                    9   \n",
       "1                      No                    9   \n",
       "2                     Yes                   10   \n",
       "3                     Yes                    5   \n",
       "4                      No                    1   \n",
       "\n",
       "   Severity of Anxiety Attack (1-10)  \n",
       "0                                 10  \n",
       "1                                  8  \n",
       "2                                  5  \n",
       "3                                  8  \n",
       "4                                  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check the first 5 rows of the dataset\n",
    "data_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Age', 'Gender', 'Occupation', 'Sleep Hours',\n",
      "       'Physical Activity (hrs/week)', 'Caffeine Intake (mg/day)',\n",
      "       'Alcohol Consumption (drinks/week)', 'Smoking',\n",
      "       'Family History of Anxiety', 'Stress Level (1-10)',\n",
      "       'Heart Rate (bpm during attack)', 'Breathing Rate (breaths/min)',\n",
      "       'Sweating Level (1-5)', 'Dizziness', 'Medication',\n",
      "       'Therapy Sessions (per month)', 'Recent Major Life Event',\n",
      "       'Diet Quality (1-10)', 'Severity of Anxiety Attack (1-10)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Check columns of the dataset\n",
    "print(f\"Columns: {data_check.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Age                                12000 non-null  int64  \n",
      " 1   Gender                             12000 non-null  object \n",
      " 2   Occupation                         12000 non-null  object \n",
      " 3   Sleep Hours                        12000 non-null  float64\n",
      " 4   Physical Activity (hrs/week)       12000 non-null  float64\n",
      " 5   Caffeine Intake (mg/day)           12000 non-null  int64  \n",
      " 6   Alcohol Consumption (drinks/week)  12000 non-null  int64  \n",
      " 7   Smoking                            12000 non-null  object \n",
      " 8   Family History of Anxiety          12000 non-null  object \n",
      " 9   Stress Level (1-10)                12000 non-null  int64  \n",
      " 10  Heart Rate (bpm during attack)     12000 non-null  int64  \n",
      " 11  Breathing Rate (breaths/min)       12000 non-null  int64  \n",
      " 12  Sweating Level (1-5)               12000 non-null  int64  \n",
      " 13  Dizziness                          12000 non-null  object \n",
      " 14  Medication                         12000 non-null  object \n",
      " 15  Therapy Sessions (per month)       12000 non-null  int64  \n",
      " 16  Recent Major Life Event            12000 non-null  object \n",
      " 17  Diet Quality (1-10)                12000 non-null  int64  \n",
      " 18  Severity of Anxiety Attack (1-10)  12000 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# 4. Check the summary of the dataset\n",
    "data_check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Check for duplicate data in the dataframe\n",
    "data_check.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the severity of anxiety attack into categories - reference: https://www.therecoveryvillage.com/mental-health/anxiety/levels-of-anxiety/\n",
    "\n",
    "def categorize_anxiety(severity):\n",
    "    if severity <= 3:\n",
    "        return 'Mild Anxiety'\n",
    "    elif 4 <= severity <= 6:\n",
    "        return 'Moderate Anxiety'\n",
    "    elif 7 <= severity <= 9:\n",
    "        return 'Severe Anxiety'\n",
    "    else:\n",
    "        return 'Panic Level Anxiety'\n",
    "\n",
    "# 6. Apply the function to create a new column for anxiety category\n",
    "data_check['Anxiety Category'] = data_check['Severity of Anxiety Attack (1-10)'].apply(categorize_anxiety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mild Anxiety': 0,\n",
       " 'Moderate Anxiety': 1,\n",
       " 'Panic Level Anxiety': 2,\n",
       " 'Severe Anxiety': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data_check['Anxiety Category Encoded'] = label_encoder.fit_transform(data_check['Anxiety Category'])\n",
    "\n",
    "# Display Mapping the label encoding results\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Drop the Severity of Anxiety Attack (1-10) column\n",
    "data_check.drop(columns = \"Severity of Anxiety Attack (1-10)\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save the processed data to a new CSV file\n",
    "data_check.to_csv('data/anxiety_attack_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Membuat Pipeline TFX Interaktif dengan Komponen-Komponen Utama***\n",
    "\n",
    "Pipeline ini terdiri dari beberapa komponen utama *TFX* yang saling berhubungan untuk *membangun*, *melatih*, dan *mengevaluasi* model machine learning. Setiap komponen akan dijelaskan secara detail dengan contoh kode yang dilengkapi dengan **magic command** untuk membuat modul Python. *Pipeline* ini bersifat modular dan dapat disesuaikan dengan kebutuhan proyek Anda. Magic command seperti *%%writefile* mempermudah pembuatan modul khusus untuk komponen seperti *Transform*, *Trainer*, dan *Tuner*.\n",
    "\n",
    "1. ```CsvExampleGen``` -> Digunakan untuk membaca data dan membaginya menjadi dua bagian: training dan evaluation.\n",
    "2. ```StatisticsGen``` -> Menghasilkan statistik data yang digunakan untuk analisis lebih lanjut dan pembuatan skema data.\n",
    "3. ```SchemaGen``` -> Membuat skema untuk dataset berdasarkan statistik yang dihitung pada langkah sebelumnya, untuk memastikan data yang masuk sesuai dengan harapan.\n",
    "4. ```ExampleValidator``` -> Memvalidasi data menggunakan skema yang telah dibuat untuk memastikan kualitas dan konsistensi data.\n",
    "5. ```Transform``` -> Melakukan transformasi pada data (misalnya, normalisasi atau encoding), guna menyiapkan data untuk pelatihan.\n",
    "6. ```Tuner``` -> Mencari hyperparameter terbaik untuk model, sehingga model dapat mencapai performa optimal berdasarkan dataset.\n",
    "7. ```Trainer``` -> Melatih model menggunakan data yang telah ditransformasi dan hyperparameter terbaik yang ditemukan oleh Tuner.\n",
    "8. ```Evaluator``` -> Mengevaluasi model yang telah dilatih menggunakan berbagai metrik kinerja, seperti Accuracy atau AUC.\n",
    "9. ```Pusher``` -> Menyimpan dan mendistribusikan model terlatih jika model memenuhi kriteria evaluasi.\n",
    "\n",
    "Komponen trainer sudah menggunakan komponen tuner. Pusher akan melakukan push model jika melebihi syarat dari BinaryAccuracy ```0.9```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Inisialisasi Komponen TFX untuk Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/components.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {COMPONENTS_MODULE_FILE}\n",
    "# Import library\n",
    "import os\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import (\n",
    "    CsvExampleGen, \n",
    "    StatisticsGen, \n",
    "    SchemaGen, \n",
    "    ExampleValidator, \n",
    "    Transform, \n",
    "    Trainer,\n",
    "    Tuner,\n",
    "    Evaluator,\n",
    "    Pusher\n",
    ")\n",
    "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2 \n",
    "from tfx.types import Channel\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
    "    LatestBlessedModelStrategy)\n",
    "\n",
    "# Fungsi untuk melakukan inisialisasi components\n",
    "def init_components(config):\n",
    "\n",
    "    \"\"\"Returns tfx components for the pipeline.\n",
    " \n",
    "    Args:\n",
    "        data_dir (str): Directory containing the dataset.\n",
    "        transform_module (str): Path to the transform module.\n",
    "        tuner_module (str): Path to the tuner module.\n",
    "        training_module (str): Path to the training module.\n",
    "        training_steps (int): Number of training steps.\n",
    "        eval_steps (int): Number of evaluation steps.\n",
    "        serving_model_dir (str): Directory to save the serving\n",
    " \n",
    "    Returns:\n",
    "        components: Tuple of TFX components.\n",
    "    \"\"\" \n",
    "    \n",
    "    # 1. Membagi dataset dengan perbandingan 9:1: Data dibagi menjadi dua bagian: 90% untuk pelatihan (train) dan 10% untuk evaluasi (eval).\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config = example_gen_pb2.SplitConfig(splits=[\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=9),\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=1)\n",
    "        ])\n",
    "    )\n",
    " \n",
    "    # 2. Komponen example gen: Menggunakan CsvExampleGen untuk menghasilkan contoh data dari file CSV yang terletak pada direktori yang ditentukan dalam konfigurasi.\n",
    "    example_gen = CsvExampleGen(\n",
    "        input_base=config[\"DATA_ROOT\"], \n",
    "        output_config=output\n",
    "    )\n",
    "    \n",
    "    # 3. Komponen statistics gen: StatisticsGen digunakan untuk menghasilkan statistik dari data, yang kemudian akan digunakan untuk validasi dan pembuatan schema.\n",
    "    statistics_gen = StatisticsGen(\n",
    "        examples=example_gen.outputs[\"examples\"]   \n",
    "    )\n",
    "    \n",
    "    # 4. Komponen schema gen: SchemaGen menghasilkan schema dari statistik yang dihasilkan oleh StatisticsGen, yang berfungsi untuk menentukan struktur data yang benar.\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"]\n",
    "    )\n",
    "    \n",
    "    # 5. Komponen example validator: ExampleValidator memastikan bahwa data yang ada sesuai dengan schema yang telah dibuat dan tidak ada data yang invalid.\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema']\n",
    "    )\n",
    "    \n",
    "    # 6. Komponen transform: Transform digunakan untuk melakukan transformasi pada data menggunakan modul yang sudah ditentukan (misalnya modul transform.py).\n",
    "    transform  = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema= schema_gen.outputs['schema'],\n",
    "        module_file=os.path.abspath(config[\"transform_module\"])\n",
    "    )\n",
    "    \n",
    "    print(\"Transform Module Path:\", os.path.abspath(config[\"transform_module\"]))\n",
    "    assert os.path.exists(config[\"transform_module\"]), \"Transform module file not found!\"\n",
    "\n",
    "\n",
    "    # 7. Komponen tuner: Tuner digunakan untuk mencari hyperparameters terbaik untuk model. Ini menggunakan modul yang sudah ditentukan (misalnya tuner.py) untuk mencari kombinasi hyperparameter yang optimal.\n",
    "    tuner = Tuner(\n",
    "        module_file=os.path.abspath(config[\"tuner_module\"]),\n",
    "        examples=transform.outputs['transformed_examples'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        train_args=trainer_pb2.TrainArgs(\n",
    "            splits=['train'], \n",
    "            num_steps=config[\"training_steps\"]),\n",
    "        eval_args=trainer_pb2.EvalArgs(\n",
    "            splits=['eval'], \n",
    "            num_steps=config[\"eval_steps\"]),\n",
    "    )\n",
    "    \n",
    "    print(\"Tuner Module Path:\", os.path.abspath(config[\"tuner_module\"]))\n",
    "    assert os.path.exists(config[\"tuner_module\"]), \"Tuner module file not found!\"\n",
    "    \n",
    "    # 8. Komponen trainer: Trainer melatih model dengan menggunakan data yang sudah ditransformasi dan hyperparameter terbaik dari Tuner.\n",
    "    trainer  = Trainer(\n",
    "        module_file=os.path.abspath(config[\"training_module\"]),\n",
    "        examples = transform.outputs['transformed_examples'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        hyperparameters=tuner.outputs['best_hyperparameters'],\n",
    "        train_args=trainer_pb2.TrainArgs(\n",
    "            splits=['train'],\n",
    "            num_steps=config[\"training_steps\"]),\n",
    "        eval_args=trainer_pb2.EvalArgs(\n",
    "            splits=['eval'], \n",
    "            num_steps=config[\"eval_steps\"])\n",
    "    )\n",
    "\n",
    "    print(\"Training Module Path:\", os.path.abspath(config[\"training_module\"]))\n",
    "    assert os.path.exists(config[\"training_module\"]), \"Training module file not found!\"\n",
    "    \n",
    "    # 9. Komponen model resolver: ModelResolver digunakan untuk memilih model terbaik yang sudah diberkati (blessed) menggunakan strategi LatestBlessedModelStrategy, yang memastikan bahwa model yang digunakan adalah yang terbaru dan terbaik.\n",
    "    model_resolver = Resolver(\n",
    "        strategy_class= LatestBlessedModelStrategy,\n",
    "        model = Channel(type=Model),\n",
    "        model_blessing = Channel(type=ModelBlessing)\n",
    "    ).with_id('Latest_blessed_model_resolver')\n",
    "\n",
    "    metrics_specs = [\n",
    "        tfma.MetricsSpec(metrics=[\n",
    "            tfma.MetricConfig(class_name='AUC'),\n",
    "            tfma.MetricConfig(class_name=\"Precision\"),  # Removed invalid config\n",
    "            tfma.MetricConfig(class_name=\"Recall\"),  # Removed invalid config\n",
    "            tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "            tfma.MetricConfig(\n",
    "                class_name='CategoricalAccuracy',\n",
    "                threshold=tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(\n",
    "                        lower_bound={'value': 0.9}),\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                        absolute={'value': 0.0001})\n",
    "                )\n",
    "            )\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=\"Anxiety Category Encoded\")],\n",
    "        slicing_specs=[\n",
    "            tfma.SlicingSpec(),\n",
    "            ],\n",
    "        metrics_specs=metrics_specs\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 10. Komponen evaluator: Evaluator digunakan untuk mengevaluasi kinerja model dengan menggunakan metrik yang telah ditentukan seperti AUC, precision, recall, dan accuracy.\n",
    "    evaluator = Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        eval_config=eval_config)\n",
    "    \n",
    "    # 11. Komponen pusher: Pusher bertanggung jawab untuk mendorong (push) model yang telah terlatih dan dievaluasi ke sistem produksi atau direktori model yang dapat digunakan untuk penyajian.\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        model_blessing=evaluator.outputs[\"blessing\"],\n",
    "        push_destination=pusher_pb2.PushDestination(\n",
    "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "                base_directory=config[\"serving_model_dir\"]\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Fungsi ini mengembalikan semua komponen yang sudah dipersiapkan untuk digunakan dalam pipeline TFX.\n",
    "    components = (\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        tuner,\n",
    "        trainer,\n",
    "        model_resolver,\n",
    "        evaluator,\n",
    "        pusher\n",
    "    )\n",
    "    \n",
    "    # Mengembalikan komponen: Pada akhirnya, fungsi ini mengembalikan komponen-komponen tersebut dalam bentuk tuple, siap untuk digunakan dalam pipeline.\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                    int64\n",
      "Gender                                object\n",
      "Occupation                            object\n",
      "Sleep Hours                          float64\n",
      "Physical Activity (hrs/week)         float64\n",
      "Caffeine Intake (mg/day)               int64\n",
      "Alcohol Consumption (drinks/week)      int64\n",
      "Smoking                               object\n",
      "Family History of Anxiety             object\n",
      "Stress Level (1-10)                    int64\n",
      "Heart Rate (bpm during attack)         int64\n",
      "Breathing Rate (breaths/min)           int64\n",
      "Sweating Level (1-5)                   int64\n",
      "Dizziness                             object\n",
      "Medication                            object\n",
      "Therapy Sessions (per month)           int64\n",
      "Recent Major Life Event               object\n",
      "Diet Quality (1-10)                    int64\n",
      "Anxiety Category                      object\n",
      "Anxiety Category Encoded               int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Misalkan df adalah DataFrame dengan data mentah\n",
    "print(data_check.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom Age bertipe data numerik\n",
      "Kolom Sleep Hours bertipe data numerik\n",
      "Kolom Physical Activity (hrs/week) bertipe data numerik\n",
      "Kolom Caffeine Intake (mg/day) bertipe data numerik\n",
      "Kolom Alcohol Consumption (drinks/week) bertipe data numerik\n",
      "Kolom Stress Level (1-10) bertipe data numerik\n",
      "Kolom Heart Rate (bpm during attack) bertipe data numerik\n",
      "Kolom Breathing Rate (breaths/min) bertipe data numerik\n",
      "Kolom Sweating Level (1-5) bertipe data numerik\n",
      "Kolom Therapy Sessions (per month) bertipe data numerik\n",
      "Kolom Diet Quality (1-10) bertipe data numerik\n"
     ]
    }
   ],
   "source": [
    "for kolom in data_check.columns:\n",
    "    if data_check[kolom].dtype == 'int64' or data_check[kolom].dtype == 'float64':\n",
    "        print(f\"Kolom {kolom} bertipe data numerik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Modul Transformasi Fitur untuk Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_transform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRANSFORM_MODULE_FILE}\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "# Daftar numerical fitur pada dataset\n",
    "NUMERICAL_FEATURES = [\n",
    "    'Age',\n",
    "    'Sleep Hours',\n",
    "    'Physical Activity (hrs/week)',\n",
    "    'Caffeine Intake (mg/day)',\n",
    "    'Alcohol Consumption (drinks/week)',\n",
    "    'Stress Level (1-10)',\n",
    "    'Heart Rate (bpm during attack)',\n",
    "    'Breathing Rate (breaths/min)',\n",
    "    'Sweating Level (1-5)',\n",
    "    'Therapy Sessions (per month)',\n",
    "    'Diet Quality (1-10)'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'Gender',\n",
    "    'Occupation',\n",
    "    'Smoking',\n",
    "    'Family History of Anxiety',\n",
    "    'Dizziness',\n",
    "    'Medication',\n",
    "    'Recent Major Life Event'\n",
    "]\n",
    "\n",
    "# Label key\n",
    "LABEL_KEY = \"Anxiety Category Encoded\"\n",
    "\n",
    "# Fungsi untuk mengubah nama fitur yang sudah ditransformasi\n",
    "def transformed_name(key):\n",
    "    \"\"\"Renaming transformed features\"\"\"\n",
    "    return key + \"_xf\"\n",
    "\n",
    "\n",
    "\n",
    "# Fungsi untuk melakukan preprocessing\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"\n",
    "    Preprocess input features into transformed features.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary dari feature keys ke raw features.\n",
    "    \n",
    "    Returns:\n",
    "        outputs: Dictionary dari feature keys ke transformed features.\n",
    "    \"\"\"\n",
    "    outputs = {}\n",
    "\n",
    "    # 1Ô∏è‚É£ Encoding fitur kategorikal terlebih dahulu (mengubah teks jadi angka)\n",
    "    encoded_categorical_features = {}\n",
    "    for feature in CATEGORICAL_FEATURES:\n",
    "        if feature in inputs:\n",
    "            encoded_categorical_features[feature] = tft.compute_and_apply_vocabulary(\n",
    "                tf.strings.strip(tf.strings.lower(inputs[feature]))  # Normalisasi teks\n",
    "            )\n",
    "    \n",
    "    # 2Ô∏è‚É£ Gabungkan semua fitur numerik + hasil encoding ke dalam satu dictionary numerik\n",
    "    all_numeric_features = {**encoded_categorical_features}  # Mulai dengan fitur kategorikal yang sudah diencode\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        if feature in inputs:\n",
    "            all_numeric_features[feature] = tf.cast(inputs[feature], tf.float32)  # Pastikan tipe float32\n",
    "    \n",
    "    # 3Ô∏è‚É£ Lakukan normalisasi ke semua fitur yang sekarang sudah numerik\n",
    "    for feature, tensor in all_numeric_features.items():\n",
    "        outputs[transformed_name(feature)] = tft.scale_to_0_1(tensor)  # Normalisasi ke [0,1]\n",
    "    \n",
    "    # 4Ô∏è‚É£ Transformasi label target (pastikan label dalam bentuk integer)\n",
    "    if LABEL_KEY in inputs:\n",
    "        outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Moderate Anxiety       3680\n",
       "Severe Anxiety         3602\n",
       "Mild Anxiety           3531\n",
       "Panic Level Anxiety    1187\n",
       "Name: Anxiety Category, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_check[\"Anxiety Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Tuner: Modul Tuning Hyperparameter Model dengan Keras Tuner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_tuner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TUNER_MODULE_FILE}\n",
    "# Import library\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorflow_transform as tft\n",
    "import keras_tuner as kt\n",
    "from tfx.v1.components import TunerFnResult\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from anxiety_trainer import NUMERICAL_FEATURES, CATEGORICAL_FEATURES, transformed_name, input_fn\n",
    "\n",
    "\n",
    "# Model builder for hyperparameter tuning\n",
    "def model_builder(hyperparameters):\n",
    "    \"\"\"\n",
    "    This function defines a Keras model and returns the model as a\n",
    "    Keras object.\n",
    "    \"\"\"\n",
    "\n",
    "    input_features = []\n",
    "\n",
    "    for key in NUMERICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1,), name=transformed_name(key))\n",
    "        )\n",
    "        \n",
    "    for key in CATEGORICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1,), name=transformed_name(key))\n",
    "        )\n",
    "\n",
    "\n",
    "    concatenate = tf.keras.layers.concatenate(input_features)\n",
    "\n",
    "    # Hyperparameter yang lebih luas untuk optimasi lebih baik\n",
    "    unit_1 = hyperparameters.Int('unit_1', min_value=128, max_value=512, step=64)\n",
    "    dropout_1 = hyperparameters.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    unit_2 = hyperparameters.Int('unit_2', min_value=64, max_value=256, step=32)\n",
    "    dropout_2 = hyperparameters.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    unit_3 = hyperparameters.Int('unit_3', min_value=32, max_value=128, step=32)\n",
    "    dropout_3 = hyperparameters.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    learning_rate = hyperparameters.Choice('learning_rate', [0.0001, 0.0005, 0.001, 0.005])\n",
    "\n",
    "    # Membangun arsitektur model\n",
    "    deep = tf.keras.layers.Dense(unit_1, activation=\"relu\")(concatenate)\n",
    "    deep = tf.keras.layers.Dropout(dropout_1)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_2, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_2)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_3, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_3)(deep)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(deep)  # 4 kelas untuk klasifikasi\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "\n",
    "    # Kompilasi model dengan optimizer yang dituning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "    \n",
    "# Fungsi tuner untuk tuning hyperparameter\n",
    "def tuner_fn(fn_args: FnArgs):\n",
    "    \"\"\"\n",
    "    Melakukan tuning hyperparameter menggunakan Keras Tuner.\n",
    "    \"\"\"\n",
    "\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    # Ambil dataset pelatihan dan evaluasi\n",
    "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, batch_size=32)\n",
    "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, batch_size=32)\n",
    "\n",
    "    # Inisialisasi RandomSearch tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_builder,\n",
    "        objective='val_sparse_categorical_accuracy',  # Optimasi berdasarkan akurasi validasi\n",
    "        max_trials=10,\n",
    "        executions_per_trial=2,\n",
    "        directory=fn_args.working_dir,\n",
    "        project_name='anxiety_severity_tuner'\n",
    "    )\n",
    "\n",
    "    return TunerFnResult(\n",
    "        tuner=tuner,\n",
    "        fit_kwargs={\n",
    "            \"x\": train_dataset,\n",
    "            \"validation_data\": eval_dataset,\n",
    "            \"steps_per_epoch\": fn_args.train_steps,\n",
    "            \"validation_steps\": fn_args.eval_steps,\n",
    "            \"epochs\": 8\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Trainer: Modul Pelatihan dan Penyajian Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/anxiety_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_MODULE_FILE}\n",
    "# Import library\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow_transform as tft\n",
    "from tfx.v1.components import TunerFnResult\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from anxiety_transform import (\n",
    "    LABEL_KEY,\n",
    "    NUMERICAL_FEATURES,\n",
    "    CATEGORICAL_FEATURES,\n",
    "    transformed_name,\n",
    ")\n",
    "\n",
    "# Fungsi untuk membuat model dengan hyperparameter terbaik dari tuner\n",
    "def get_model(hyperparameters, show_summary=True):\n",
    "    \"\"\"\n",
    "    Membuat model dengan hyperparameter terbaik dari tuner.\n",
    "    \"\"\"\n",
    "\n",
    "    input_features = []\n",
    "\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        input_features.append(tf.keras.Input(shape=(1,), name=transformed_name(feature)))\n",
    "        \n",
    "    for feature in CATEGORICAL_FEATURES:\n",
    "        input_features.append(tf.keras.Input(shape=(1,), name=transformed_name(feature)))\n",
    "\n",
    "    concatenate = tf.keras.layers.concatenate(input_features)\n",
    "\n",
    "    # Ambil hyperparameter terbaik dari tuner\n",
    "    unit_1 = hyperparameters.get('unit_1', 128)\n",
    "    dropout_1 = hyperparameters.get('dropout_1', 0.2)\n",
    "    unit_2 = hyperparameters.get('unit_2', 64)\n",
    "    dropout_2 = hyperparameters.get('dropout_2', 0.2)\n",
    "    unit_3 = hyperparameters.get('unit_3', 32)\n",
    "    dropout_3 = hyperparameters.get('dropout_3', 0.2)\n",
    "    learning_rate = hyperparameters.get('learning_rate', 0.001)\n",
    "\n",
    "    # Lapisan Dense berdasarkan hyperparameter yang dituning\n",
    "    deep = tf.keras.layers.Dense(unit_1, activation=\"relu\")(concatenate)\n",
    "    deep = tf.keras.layers.Dropout(dropout_1)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_2, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_2)(deep)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(unit_3, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dropout(dropout_3)(deep)\n",
    "\n",
    "    # Output layer untuk klasifikasi multi-kelas\n",
    "    outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(deep)\n",
    "\n",
    "    # Buat model\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "\n",
    "    # Kompilasi model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Fungsi untuk membaca data yang sudah di kompres\n",
    "def gzip_reader_fn(filenames):\n",
    "    \"\"\"Loads compressed data\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "\n",
    "# Fungsi untuk mendapatkan fitur yang sudah di transform\n",
    "def get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        feature_spec.pop(LABEL_KEY)\n",
    "        parsed_features = tf.io.parse_example(\n",
    "            serialized_tf_examples, feature_spec\n",
    "        )\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "# Fungsi untuk membuat dataset\n",
    "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
    "    \"\"\"Generates features and labels for tuning/training.\"\"\"\n",
    "    transformed_feature_spec = (\n",
    "        tf_transform_output.transformed_feature_spec().copy()\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=gzip_reader_fn,\n",
    "        label_key=transformed_name(LABEL_KEY),\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def run_fn(fn_args):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melatih model berdasarkan hasil tuning dari tuner.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hasil transformasi fitur\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "    # Ambil hyperparameters terbaik dari tuner\n",
    "    hyperparameters = fn_args.hyperparameters\n",
    "\n",
    "    # Ambil dataset pelatihan dan evaluasi\n",
    "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, batch_size=64)\n",
    "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, batch_size=64)\n",
    "\n",
    "    # Buat model dengan hyperparameter terbaik\n",
    "    model = get_model(hyperparameters)\n",
    "\n",
    "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=\"batch\")\n",
    "    \n",
    "    # Tambahkan callback untuk optimalisasi training\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=8, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001\n",
    "    )\n",
    "    \n",
    "    # Latih model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        callbacks=[tensorboard_callback, early_stopping, reduce_lr],\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    # Simpan model untuk serving\n",
    "    signatures = {\n",
    "        \"serving_default\": get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    model.save(fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Inisialisasi Pipeline Lokal dengan Apache Beam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_local_pipeline(\n",
    "    components, pipeline_root: Text\n",
    ") -> tfx_pipeline.Pipeline:  # Use the aliased name here\n",
    "    \n",
    "    logging.info(f\"Pipeline root set to: {pipeline_root}\")\n",
    "\n",
    "    \n",
    "    return tfx_pipeline.Pipeline(  # Use the aliased name here\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=pipeline_root,\n",
    "        components=components,\n",
    "        enable_cache=True,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
    "            METADATA_PATH\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. Menjalankan Pipeline Lokal Menggunakan Apache Beam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 35s]\n",
      "val_sparse_categorical_accuracy: 0.30418750643730164\n",
      "\n",
      "Best val_sparse_categorical_accuracy So Far: 0.3136874884366989\n",
      "Total elapsed time: 00h 15m 50s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Int', 'config': {'name': 'unit_1', 'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 64, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_1', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'unit_2', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_2', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'unit_3', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Float', 'config': {'name': 'dropout_3', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.0005, 0.001, 0.005], 'ordered': True}}], 'values': {'unit_1': 448, 'dropout_1': 0.2, 'unit_2': 224, 'dropout_2': 0.2, 'unit_3': 128, 'dropout_3': 0.2, 'learning_rate': 0.0005}}\n",
      "INFO:absl:Best Hyperparameters are written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Tuner\\best_hyperparameters\\78\\best_hyperparameters.txt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 78 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'best_hyperparameters': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Tuner\\\\best_hyperparameters\\\\78\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Tuner:best_hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 78\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Tuner is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Tuner\\.system\\executor_execution\\78\\.temp\\78\\anxiety_severity_tuner\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002447A8067F0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 448\n",
      "dropout_1: 0.2\n",
      "unit_2: 224\n",
      "dropout_2: 0.2\n",
      "unit_3: 128\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0005\n",
      "Score: 0.3136874884366989\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 128\n",
      "dropout_1: 0.1\n",
      "unit_2: 128\n",
      "dropout_2: 0.5\n",
      "unit_3: 96\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.31162498891353607\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 128\n",
      "dropout_1: 0.5\n",
      "unit_2: 160\n",
      "dropout_2: 0.1\n",
      "unit_3: 32\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.3072499930858612\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 128\n",
      "dropout_1: 0.4\n",
      "unit_2: 128\n",
      "dropout_2: 0.30000000000000004\n",
      "unit_3: 32\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0001\n",
      "Score: 0.30543749034404755\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 384\n",
      "dropout_1: 0.30000000000000004\n",
      "unit_2: 160\n",
      "dropout_2: 0.4\n",
      "unit_3: 96\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.005\n",
      "Score: 0.30418750643730164\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 320\n",
      "dropout_1: 0.4\n",
      "unit_2: 160\n",
      "dropout_2: 0.2\n",
      "unit_3: 32\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.005\n",
      "Score: 0.30268749594688416\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 256\n",
      "dropout_1: 0.2\n",
      "unit_2: 256\n",
      "dropout_2: 0.30000000000000004\n",
      "unit_3: 128\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.005\n",
      "Score: 0.30143749713897705\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 192\n",
      "dropout_1: 0.1\n",
      "unit_2: 192\n",
      "dropout_2: 0.5\n",
      "unit_3: 32\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.0005\n",
      "Score: 0.3006249964237213\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 256\n",
      "dropout_1: 0.2\n",
      "unit_2: 192\n",
      "dropout_2: 0.2\n",
      "unit_3: 96\n",
      "dropout_3: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.29756250977516174\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "unit_1: 384\n",
      "dropout_1: 0.1\n",
      "unit_2: 128\n",
      "dropout_2: 0.4\n",
      "unit_3: 32\n",
      "dropout_3: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "Score: 0.2929375022649765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:node Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 250,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 79\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=79, input_dict={'transform_graph': [Artifact(artifact: id: 125\n",
      "type_id: 24\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Transform\\\\transform_graph\\\\76\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Transform:transform_graph:0\"\n",
      "create_time_since_epoch: 1739108021532\n",
      "last_update_time_since_epoch: 1739108021532\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'hyperparameters': [Artifact(artifact: id: 127\n",
      "type_id: 27\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Tuner\\\\best_hyperparameters\\\\78\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Tuner:best_hyperparameters:0\"\n",
      "create_time_since_epoch: 1739108979818\n",
      "last_update_time_since_epoch: 1739108979818\n",
      ", artifact_type: id: 27\n",
      "name: \"HyperParameters\"\n",
      ")], 'schema': [Artifact(artifact: id: 117\n",
      "type_id: 20\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\SchemaGen\\\\schema\\\\75\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:SchemaGen:schema:0\"\n",
      "create_time_since_epoch: 1739107963933\n",
      "last_update_time_since_epoch: 1739107963933\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 119\n",
      "type_id: 15\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Transform\\\\transformed_examples\\\\76\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"eval\\\", \\\"train\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Transform:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Transform:transformed_examples:0\"\n",
      "create_time_since_epoch: 1739108021531\n",
      "last_update_time_since_epoch: 1739108021531\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model_run\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'custom_config': 'null', 'module_path': 'anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl', 'eval_args': '{\\n  \"num_steps\": 250,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\executor_execution\\\\79\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\stateful_working_dir\\\\20250209-203233.129249', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\.system\\\\executor_execution\\\\79\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 250,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250209-203233.129249')\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'custom_config': 'null', 'module_path': 'anxiety_trainer@RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl', 'eval_args': '{\\n  \"num_steps\": 250,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'} 'run_fn'\n",
      "INFO:absl:Installing 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['c:\\\\Users\\\\rendi\\\\anaconda3\\\\envs\\\\tfx-beam\\\\python.exe', '-m', 'pip', 'install', '--target', 'C:\\\\Users\\\\rendi\\\\AppData\\\\Local\\\\Temp\\\\tmp0up3fst8', 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl']\n",
      "INFO:absl:Successfully installed 'RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+4e0c4d9c0dc29ec0dc0c4da58f27981c712da2371f96315cc72ca81e92256ab9-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Sleep Hours_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Physical Activity (hrs/week)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Caffeine Intake (mg/day)_xf (I  [(None, 1)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Alcohol Consumption (drinks/we  [(None, 1)]         0           []                               \n",
      " ek)_xf (InputLayer)                                                                              \n",
      "                                                                                                  \n",
      " Stress Level (1-10)_xf (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Heart Rate (bpm during attack)  [(None, 1)]         0           []                               \n",
      " _xf (InputLayer)                                                                                 \n",
      "                                                                                                  \n",
      " Breathing Rate (breaths/min)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Sweating Level (1-5)_xf (Input  [(None, 1)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " Therapy Sessions (per month)_x  [(None, 1)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Diet Quality (1-10)_xf (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Gender_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Occupation_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Smoking_xf (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Family History of Anxiety_xf (  [(None, 1)]         0           []                               \n",
      " InputLayer)                                                                                      \n",
      "                                                                                                  \n",
      " Dizziness_xf (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Medication_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Recent Major Life Event_xf (In  [(None, 1)]         0           []                               \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 18)           0           ['Age_xf[0][0]',                 \n",
      "                                                                  'Sleep Hours_xf[0][0]',         \n",
      "                                                                  'Physical Activity (hrs/week)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Caffeine Intake (mg/day)_xf[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'Alcohol Consumption (drinks/wee\n",
      "                                                                 k)_xf[0][0]',                    \n",
      "                                                                  'Stress Level (1-10)_xf[0][0]', \n",
      "                                                                  'Heart Rate (bpm during attack)_\n",
      "                                                                 xf[0][0]',                       \n",
      "                                                                  'Breathing Rate (breaths/min)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Sweating Level (1-5)_xf[0][0]',\n",
      "                                                                  'Therapy Sessions (per month)_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Diet Quality (1-10)_xf[0][0]', \n",
      "                                                                  'Gender_xf[0][0]',              \n",
      "                                                                  'Occupation_xf[0][0]',          \n",
      "                                                                  'Smoking_xf[0][0]',             \n",
      "                                                                  'Family History of Anxiety_xf[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'Dizziness_xf[0][0]',           \n",
      "                                                                  'Medication_xf[0][0]',          \n",
      "                                                                  'Recent Major Life Event_xf[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          2432        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            132         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,900\n",
      "Trainable params: 12,900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3177 - sparse_categorical_accuracy: 0.3073 - val_loss: 1.3179 - val_sparse_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3114 - sparse_categorical_accuracy: 0.3154 - val_loss: 1.3198 - val_sparse_categorical_accuracy: 0.2896 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3054 - sparse_categorical_accuracy: 0.3265 - val_loss: 1.3240 - val_sparse_categorical_accuracy: 0.2923 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2986 - sparse_categorical_accuracy: 0.3378 - val_loss: 1.3375 - val_sparse_categorical_accuracy: 0.2859 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2828 - sparse_categorical_accuracy: 0.3575 - val_loss: 1.3458 - val_sparse_categorical_accuracy: 0.2777 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2743 - sparse_categorical_accuracy: 0.3644 - val_loss: 1.3564 - val_sparse_categorical_accuracy: 0.2802 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2648 - sparse_categorical_accuracy: 0.3786 - val_loss: 1.3605 - val_sparse_categorical_accuracy: 0.2879 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2537 - sparse_categorical_accuracy: 0.3874 - val_loss: 1.3680 - val_sparse_categorical_accuracy: 0.2710 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2484 - sparse_categorical_accuracy: 0.3920 - val_loss: 1.3695 - val_sparse_categorical_accuracy: 0.2681 - lr: 2.5000e-04\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\79\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\79\\Format-Serving\\assets\n",
      "INFO:absl:Training complete. Model written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\79\\Format-Serving. ModelRun written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model_run\\79\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 79 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model_run\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 79\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Trainer is finished.\n",
      "INFO:absl:node Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"CategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"Anxiety Category Encoded\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 80\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=80, input_dict={'examples': [Artifact(artifact: id: 115\n",
      "type_id: 15\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\CsvExampleGen\\\\examples\\\\73\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:976219,xor_checksum:1739107949,sum_checksum:1739107949\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:CsvExampleGen:examples:0\"\n",
      "create_time_since_epoch: 1739107959950\n",
      "last_update_time_since_epoch: 1739107959950\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'baseline_model': [], 'model': [Artifact(artifact: id: 129\n",
      "type_id: 29\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "create_time_since_epoch: 1739109040124\n",
      "last_update_time_since_epoch: 1739109040124\n",
      ", artifact_type: id: 29\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\evaluation\\\\80\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Evaluator:evaluation:0\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\80\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}), exec_properties={'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\executor_execution\\\\80\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\stateful_working_dir\\\\20250209-203233.129249', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\.system\\\\executor_execution\\\\80\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"CategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"Anxiety Category Encoded\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250209-203233.129249')\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'} 'custom_eval_shared_model'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Trainer\\model\\79\\Format-Serving as  model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000244012BEA90> and <keras.engine.input_layer.InputLayer object at 0x0000024446D9AAF0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000244012BEA90> and <keras.engine.input_layer.InputLayer object at 0x0000024446D9AAF0>).\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"CategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.9\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Anxiety Category Encoded\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'} 'custom_extractors'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Anxiety Category Encoded\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"CategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.9\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024407B9DD00> and <keras.engine.input_layer.InputLayer object at 0x0000024446D9AF70>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024407B9DD00> and <keras.engine.input_layer.InputLayer object at 0x0000024446D9AF70>).\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.9 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002457F81C820> and <keras.engine.input_layer.InputLayer object at 0x000002447BDF7130>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002457F81C820> and <keras.engine.input_layer.InputLayer object at 0x000002447BDF7130>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002456CED80A0> and <keras.engine.input_layer.InputLayer object at 0x000002456062D250>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002456CED80A0> and <keras.engine.input_layer.InputLayer object at 0x000002456062D250>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000244465E2BE0> and <keras.engine.input_layer.InputLayer object at 0x000002457D33B2E0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000244465E2BE0> and <keras.engine.input_layer.InputLayer object at 0x000002457D33B2E0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002458F3ADD30> and <keras.engine.input_layer.InputLayer object at 0x000002458F3579A0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002458F3ADD30> and <keras.engine.input_layer.InputLayer object at 0x000002458F3579A0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024407AC5190> and <keras.engine.input_layer.InputLayer object at 0x000002447A62E130>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024407AC5190> and <keras.engine.input_layer.InputLayer object at 0x000002447A62E130>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024590BD36D0> and <keras.engine.input_layer.InputLayer object at 0x0000024590CDD5E0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000024590BD36D0> and <keras.engine.input_layer.InputLayer object at 0x0000024590CDD5E0>).\n",
      "INFO:absl:Evaluation complete. Results written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\evaluation\\80.\n",
      "INFO:absl:Checking validation results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rendi\\anaconda3\\envs\\tfx-beam\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:109: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rendi\\anaconda3\\envs\\tfx-beam\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:109: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:absl:Blessing result False written to RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\blessing\\80.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 80 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\evaluation\\\\80\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Evaluator:evaluation:0\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\80\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}) for execution 80\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Evaluator is finished.\n",
      "INFO:absl:node Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model_dir\\\\\\\\anxiety-model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 81\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=81, input_dict={'model_blessing': [Artifact(artifact: id: 131\n",
      "type_id: 33\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Evaluator\\\\blessing\\\\80\"\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\79\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 129\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Evaluator:blessing:0\"\n",
      "create_time_since_epoch: 1739109052949\n",
      "last_update_time_since_epoch: 1739109052949\n",
      ", artifact_type: id: 33\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 129\n",
      "type_id: 29\n",
      "uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Trainer\\\\model\\\\79\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Trainer:model:0\"\n",
      "create_time_since_epoch: 1739109040124\n",
      "last_update_time_since_epoch: 1739109040124\n",
      ", artifact_type: id: 29\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\pushed_model\\\\81\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model_dir\\\\\\\\anxiety-model\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\executor_execution\\\\81\\\\executor_output.pb', stateful_working_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\stateful_working_dir\\\\20250209-203233.129249', tmp_dir='RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\.system\\\\executor_execution\\\\81\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20250209-203233.129249\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"anxiety-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20250209-203233.129249\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"anxiety-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model_dir\\\\\\\\anxiety-model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"anxiety-pipeline\"\n",
      ", pipeline_run_id='20250209-203233.129249')\n",
      "INFO:absl:Model on RENDIKA_NURHARTANTO_SUHARTO-pipeline\\anxiety-pipeline\\Evaluator\\blessing\\80 was not blessed by model validation\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 81 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"RENDIKA_NURHARTANTO_SUHARTO-pipeline\\\\anxiety-pipeline\\\\Pusher\\\\pushed_model\\\\81\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"anxiety-pipeline:20250209-203233.129249:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"anxiety-pipeline:20250209-203233.129249:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 81\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "from modules.components import init_components\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "config = {\n",
    "    \"DATA_ROOT\": DATA_ROOT,\n",
    "    \"training_module\": TRAINER_MODULE_FILE,\n",
    "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
    "    \"tuner_module\": TUNER_MODULE_FILE,\n",
    "    \"training_steps\": 1000,\n",
    "    \"eval_steps\": 250,\n",
    "    \"serving_model_dir\": SERVING_MODEL_DIR,\n",
    "}\n",
    "\n",
    "components = init_components(config)\n",
    "\n",
    "pipeline = init_local_pipeline(components, PIPELINE_ROOT)\n",
    "BeamDagRunner().run(pipeline=pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx-beam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
